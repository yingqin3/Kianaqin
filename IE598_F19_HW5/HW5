import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import pylab
import seaborn as sns
import scipy.stats as stats
from pandas import DataFrame
data=pd.read_csv('treasury yield curve data.csv')
df=data.drop(columns='Date')
df.dropna(inplace=True)
print('number of rows and columns are:',df.shape)
print(df.info())
df.describe()

print('choose some important indexes to draw QQ-plot: SVENF01„ÄÅAdj_Close')
stats.probplot(df['SVENF01'], dist='norm', plot=pylab)
pylab.show()
stats.probplot(df['Adj_Close'], dist='norm', plot=pylab)
pylab.show()

print('draw ECDF with SVENF30 and Adj_Close :  ')
x=np.sort(df['SVENF30'])
y=np.arange(1,len(x)+1)/len(x)
_=plt.plot(x,y,marker='.',linestyle='none')
_=plt.xlabel('SVENF30')
_=plt.ylabel('ECDF')
plt.show()
a=np.sort(df['Adj_Close'])
b=np.arange(1,len(a)+1)/len(a)
_=plt.plot(a,b,marker='.',linestyle='none')
_=plt.xlabel('Adj_Closee')
_=plt.ylabel('ECDF')
plt.show()

print('Covariance:')
cov=np.cov(df)
print(cov)
print('Pearson correlation coefficient:')
coef=np.corrcoef(df)
print(coef)

cols=['SVENF10','SVENF20','SVENF30','Adj_Close']
sns.pairplot(df[cols], size=2.5)
plt.tight_layout()
plt.show()

from sklearn.model_selection import train_test_split
X=df.drop('Adj_Close',axis=1).values
y=df['Adj_Close'].values
X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.15, random_state=42)
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train_std = sc.fit_transform(X_train)
X_test_std = sc.transform(X_test)
cov_mat = np.cov(X_train_std.T)
eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)
tot = sum(eigen_vals)
var_exp = [(i / tot) for i in sorted(eigen_vals, reverse=True)]
cum_var_exp = np.cumsum(var_exp)
import matplotlib.pyplot as plt
plt.bar(range(1,31), var_exp, alpha=0.5, align='center',label='individual explained variance')
plt.step(range(1,31), cum_var_exp, where='mid',label='cumulative explained variance')
plt.ylabel('Explained variance ratio')
plt.xlabel('Principal component index')
plt.legend(loc='best')
plt.show()

from sklearn.decomposition import PCA 
pca = PCA(n_components = 3) 
X_train_pca = pca.fit_transform(X_train_std) 
X_test_pca = pca.transform(X_test_std) 
explained_variance_ratio = pca.explained_variance_ratio_ 
print('explained_variance_ratio of n_components=3:', explained_variance_ratio)
print('explained_variance of 3 componnet version:', pca.explained_variance_ )
cov_mat = np.cov(X_train_pca.T)
eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)
tot = sum(eigen_vals)
var_exp = [(i / tot) for i in sorted(eigen_vals, reverse=True)]
cum_var_exp = np.cumsum(var_exp)
import matplotlib.pyplot as plt
plt.bar(range(1,4), var_exp, alpha=0.5, align='center',label='individual explained variance')
plt.step(range(1,4), cum_var_exp, where='mid',label='cumulative explained variance')
plt.ylabel('Explained variance ratio')
plt.xlabel('Principal component index')
plt.legend(loc='best')
plt.show()

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
reg=LinearRegression()
reg.fit(X_train,y_train)
y_train_pred=reg.predict(X_train)
y_pred=reg.predict(X_test)
print("R^2 train: {}".format(reg.score(X_train, y_train)))
print("R^2 test: {}".format(reg.score(X_test, y_test)))
rmse = np.sqrt(mean_squared_error(y_test,y_pred))
print("RMSE test: {}".format(rmse))
print('RMSE train:', np.sqrt(mean_squared_error(y_train,y_train_pred)))

from sklearn.svm import SVR
SVM = SVR(kernel = 'linear')
SVM.fit(X_train, y_train)
SVM_train_pred = SVM.predict(X_train)
SVM_test_pred = SVM.predict(X_test)
print("R^2 train: {}".format(SVM.score(X_train, y_train)))
print("R^2 test: {}".format(SVM.score(X_test, y_test)))
rmse = np.sqrt(mean_squared_error(y_test,SVM_test_pred))
print("RMSE test: {}".format(rmse))
print('RMSE train:', np.sqrt(mean_squared_error(y_train,SVM_train_pred)))

sc_x = StandardScaler()
sc_y = StandardScaler()
X_std = sc_x.fit_transform(X)
y_std = sc_y.fit_transform(y[:,np.newaxis]).flatten()
X_train_pca, X_test_pca, y_train, y_test = train_test_split(pca.transform(X_std), y_std, test_size = 0.15, random_state = 42)
reg_pca=LinearRegression()
reg_pca.fit(X_train_pca,y_train)
y_train_pca_pred=reg_pca.predict(X_train_pca)
y_pca_pred=reg_pca.predict(X_test_pca)
print("R^2 train: {}".format(reg_pca.score(X_train_pca, y_train)))
print("R^2 test: {}".format(reg_pca.score(X_test_pca, y_test)))
rmse = np.sqrt(mean_squared_error(y_test,y_pca_pred))
print("RMSE test: {}".format(rmse))
print('RMSE train:', np.sqrt(mean_squared_error(y_train,y_train_pca_pred)))

SVM.fit(X_train_pca, y_train)
SVM_train_pred_pca= SVM.predict(X_train_pca)
SVM_test_pred_pca= SVM.predict(X_test_pca)
print("R^2 train: {}".format(SVM.score(X_train_pca, y_train)))
print("R^2 test: {}".format(SVM.score(X_test_pca, y_test)))
rmse = np.sqrt(mean_squared_error(y_test,SVM_test_pred_pca))
print("RMSE test: {}".format(rmse))
print('RMSE train:', np.sqrt(mean_squared_error(y_train,SVM_train_pred_pca)))

print('My name is Ying Qin')
print('My NetID is yingqin3')
print('I hereby certify that I have read the University policy on Academic Integrity and that I am not in violation.')
